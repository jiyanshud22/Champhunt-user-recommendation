{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFX4dS9Is3bzBi+v/CmxqQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiyanshud22/Champhunt-user-recommendation/blob/main/ball_photo_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "N5HwTvYJC319"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width, height = 280, 560 # size of output image (few functions use it)"
      ],
      "metadata": {
        "id": "hQRrHHoNotOK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_table():\n",
        "\n",
        "    # new generated img\n",
        "    img = np.zeros((height,width,3), dtype=np.uint8) # create 2D table image\n",
        "    img[:, :] = [0, 180, 10] # setting RGB colors to green pool table color, (0,180,10)=certain green\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    # create circle in the right size\n",
        "    cv2.circle(img, (int(width/2),int(height/5)), # center of circle\n",
        "               int((width/3)/2), # radius\n",
        "               (50,255,50)) # color\n",
        "\n",
        "    # delete half of circle by coloring in green color\n",
        "    img[int(height/5):height,0:width] = [0, 180, 10]\n",
        "    # create line\n",
        "    cv2.line(img,(0,int(height/5)),(width,int(height/5)),(50,255,50))\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "5Q48-4x5otLJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_holes(input_img, color3 = (200,140,0)):\n",
        "\n",
        "    color = (190, 190, 190) # gray color\n",
        "    color2 = (120, 120, 120) #  gray color, for circles (holes) on generated img\n",
        "\n",
        "    img = input_img.copy() # make a copy of input image\n",
        "\n",
        "    # borders\n",
        "    cv2.line(img,(0,0),(width,0),color3,3) # top\n",
        "    cv2.line(img,(0,height),(width,height),color3,3) # bot\n",
        "    cv2.line(img,(0,0),(0,height),color3,3) # left\n",
        "    cv2.line(img,(width,0),(width,height),color3,3) # right\n",
        "\n",
        "    # adding circles to represent holes on table\n",
        "    cv2.circle(img, (0, 0), 11,color, -1) # top right\n",
        "    cv2.circle(img, (width,0), 11, color, -1) # top left\n",
        "    cv2.circle(img, (0,height), 11, color, -1) # bot left\n",
        "    cv2.circle(img, (width,height), 11, color, -1) # bot right\n",
        "    cv2.circle(img, (width,int(height/2)), 8, color, -1) # mid right\n",
        "    cv2.circle(img, (0,int(height/2)), 8, color, -1) # mid left\n",
        "\n",
        "    # adding another, smaller circles to the previous ones\n",
        "    cv2.circle(img, (0, 0), 9,color2, -1) # top right\n",
        "    cv2.circle(img, (width,0), 9, color2, -1) # top left\n",
        "    cv2.circle(img, (0,height), 9, color2, -1) # bot left\n",
        "    cv2.circle(img, (width,height), 9, color2, -1) # bot right\n",
        "    cv2.circle(img, (width,int(height/2)), 6, color2, -1) # mid right\n",
        "    cv2.circle(img, (0,int(height/2)), 6, color2, -1) # mid left\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "gUzSKTHDotGA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_balls(ctrs,background = create_table(), radius=7, size = -1, img = 0):\n",
        "\n",
        "    K = np.ones((3,3),np.uint8) # filter\n",
        "\n",
        "    final = background.copy() # canvas\n",
        "    mask = np.zeros((560, 280),np.uint8) # empty image, same size as 2d generated final output\n",
        "\n",
        "\n",
        "    for x in range(len(ctrs)): # for all contours\n",
        "\n",
        "        # find center of contour\n",
        "        M = cv2.moments(ctrs[x])\n",
        "        cX = int(M['m10']/M['m00']) # X pos of contour center\n",
        "        cY = int(M['m01']/M['m00']) # Y pos\n",
        "\n",
        "        # find color average inside contour\n",
        "        mask[...]=0 # reset the mask for every ball\n",
        "        cv2.drawContours(mask,ctrs,x,255,-1) # draws mask for each contour\n",
        "        mask =  cv2.erode(mask,K,iterations = 3) # erode mask several times to filter green color around balls contours\n",
        "\n",
        "\n",
        "        # balls design:\n",
        "\n",
        "\n",
        "        # circle to represent snooker ball\n",
        "        final = cv2.circle(final, # img to draw on\n",
        "                           (cX,cY), # position on img\n",
        "                           radius, # radius of circle - size of drawn snooker ball\n",
        "                           cv2.mean(img,mask), # color mean of each contour-color of each ball (src_img=transformed img)\n",
        "                           size) # -1 to fill ball with color\n",
        "\n",
        "        # add black color around the drawn ball (for cosmetics)\n",
        "        final = cv2.circle(final, (cX,cY), radius, 0, 1)\n",
        "\n",
        "        # small circle for light reflection\n",
        "        final = cv2.circle(final, (cX-2,cY-2), 2, (255,255,255), -1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return final"
      ],
      "metadata": {
        "id": "XVaH4RcPotCq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_ctrs(ctrs, min_s = 90, max_s = 358, alpha = 3.445):\n",
        "\n",
        "    filtered_ctrs = [] # list for filtered contours\n",
        "\n",
        "    for x in range(len(ctrs)): # for all contours\n",
        "\n",
        "        rot_rect = cv2.minAreaRect(ctrs[x]) # area of rectangle around contour\n",
        "        w = rot_rect[1][0] # width of rectangle\n",
        "        h = rot_rect[1][1] # height\n",
        "        area = cv2.contourArea(ctrs[x]) # contour area\n",
        "\n",
        "\n",
        "        if (h*alpha<w) or (w*alpha<h): # if the contour isnt the size of a snooker ball\n",
        "            continue # do nothing\n",
        "\n",
        "        if (area < min_s) or (area > max_s): # if the contour area is too big/small\n",
        "            continue # do nothing\n",
        "\n",
        "        # if it failed previous statements then it is most likely a ball\n",
        "        filtered_ctrs.append(ctrs[x]) # add contour to filtered cntrs list\n",
        "\n",
        "\n",
        "    return filtered_ctrs # returns filtere contours"
      ],
      "metadata": {
        "id": "uRAEu7-Ros_Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_balls(src):\n",
        "    final = create_table()\n",
        "\n",
        "    # warp perspective\n",
        "    matrix = cv2.getPerspectiveTransform(pts1,pts2) # getting perspective by 4 points of each image\n",
        "    transformed = cv2.warpPerspective(src, matrix, (width,height)) # warps perpective to new image\n",
        "\n",
        "    # apply blur\n",
        "    transformed_blur = cv2.GaussianBlur(transformed,(5,5),cv2.BORDER_DEFAULT) # blur applied\n",
        "    blur_RGB = cv2.cvtColor(transformed_blur, cv2.COLOR_BGR2RGB) # rgb version\n",
        "\n",
        "    # mask\n",
        "    hsv = cv2.cvtColor(blur_RGB, cv2.COLOR_RGB2HSV) # convert to hsv\n",
        "    mask = cv2.inRange(hsv, lower, upper) # table's mask\n",
        "\n",
        "    # filter mask\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    mask_closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel) # dilate->erode\n",
        "\n",
        "    # apply threshold\n",
        "    ret,mask_inv = cv2.threshold(mask_closing,5,255,cv2.THRESH_BINARY_INV) # apply threshold\n",
        "\n",
        "    # create image with masked objects on table\n",
        "    masked_objects = cv2.bitwise_and(transformed,transformed, mask=mask_inv) # masked image\n",
        "\n",
        "    # find contours and filter them\n",
        "    ctrs, hierarchy = cv2.findContours(mask_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # find contours\n",
        "    ctrs = filter_ctrs(ctrs) # filter contours by sizes and shapes\n",
        "\n",
        "    # draw table+balls\n",
        "    final = draw_balls(ctrs,radius=8,img=transformed) # draw all found contours\n",
        "    final = draw_holes(final) # draw holes\n",
        "\n",
        "    return final"
      ],
      "metadata": {
        "id": "CdaWauhvos8p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_ctrs_color(ctrs, input_img):\n",
        "\n",
        "    K = np.ones((3,3),np.uint8) # filter\n",
        "    output = input_img.copy() #np.zeros(input_img.shape,np.uint8) # empty img\n",
        "    gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY) # gray version\n",
        "    mask = np.zeros(gray.shape,np.uint8) # empty mask\n",
        "\n",
        "    for i in range(len(ctrs)): # for all contours\n",
        "\n",
        "        # find center of contour\n",
        "        M = cv2.moments(ctrs[i])\n",
        "        cX = int(M['m10']/M['m00']) # X pos of contour center\n",
        "        cY = int(M['m01']/M['m00']) # Y pos\n",
        "\n",
        "        mask[...]=0 # reset the mask for every ball\n",
        "\n",
        "        cv2.drawContours(mask,ctrs,i,255,-1) # draws the mask of current contour (every ball is getting masked each iteration)\n",
        "\n",
        "        mask =  cv2.erode(mask,K,iterations=3) # erode mask to filter green color around the balls contours\n",
        "\n",
        "        output = cv2.circle(output, # img to draw on\n",
        "                         (cX,cY), # position on img\n",
        "                         20, # radius of circle - size of drawn snooker ball\n",
        "                         cv2.mean(input_img,mask), # color mean of each contour-color of each ball (src_img=transformed img)\n",
        "                         -1) # -1 to fill ball with color\n",
        "    return output"
      ],
      "metadata": {
        "id": "HfqtnomKos5g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_rectangles(ctrs, img):\n",
        "\n",
        "    output = img.copy()\n",
        "\n",
        "    for i in range(len(ctrs)):\n",
        "\n",
        "        M = cv2.moments(ctrs[i]) # moments\n",
        "        rot_rect = cv2.minAreaRect(ctrs[i])\n",
        "        w = rot_rect[1][0] # width\n",
        "        h = rot_rect[1][1] # height\n",
        "\n",
        "        box = np.int64(cv2.boxPoints(rot_rect))\n",
        "        cv2.drawContours(output,[box],0,(255,100,0),2) # draws box\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "Sjy_xqsYos1j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'P6_Snooker.mp4'\n",
        "\n",
        "# first frame from the original video\n",
        "cap = cv2.VideoCapture(name)\n",
        "ret, frame = cap.read()\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # take first frame\n",
        "\n",
        "# loop frames and take few different frames for later\n",
        "for i in range(1430):\n",
        "    ret, frame2 = cap.read() # frame2 = the 1430th frame (frame example #1)\n",
        "    if i == 1050:\n",
        "        frame3 = frame2.copy() # frame3 = the 1000th frame (frame example #2)\n",
        "    if i == 263:\n",
        "        frame4 = frame2.copy() # frame4 = the 263th frame (frame example #3)\n",
        "\n",
        "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
        "frame3 = cv2.cvtColor(frame3, cv2.COLOR_BGR2RGB)\n",
        "frame4 = cv2.cvtColor(frame4, cv2.COLOR_BGR2RGB) # another frames\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.imshow(frame)\n",
        "plt.title('first frame')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Gl2E_B3rosyp",
        "outputId": "10916c8d-566e-481f-8da7-7accc0b98669"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ce3ff725919c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take first frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# loop frames and take few different frames for later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization:\n",
        "\n",
        "# red points on corners of original table\n",
        "table = frame.copy() # add points to pool table corners\n",
        "cv2.circle(table, (160, 380), 8, 255, -1) # bot left\n",
        "cv2.circle(table, (690, 380), 8, 255, -1) # bot right\n",
        "cv2.circle(table, (255, 60), 8, 255, -1) # top left\n",
        "cv2.circle(table, (590, 60), 8, 255, -1) # top right\n",
        "\n",
        "# red points on corners of generated table\n",
        "img = np.zeros((height,width,3), dtype=np.uint8)\n",
        "new_img = img.copy() # add points to edges of img\n",
        "cv2.circle(new_img, (0,0), 8, 255, -1) # bot left\n",
        "cv2.circle(new_img, (width,0), 8, 255, -1) # bot right\n",
        "cv2.circle(new_img, (0,height), 8, 255, -1) # top left\n",
        "cv2.circle(new_img, (width,height), 8, 255, -1) # top right\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(table)\n",
        "plt.title('FROM')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(new_img)\n",
        "plt.title('TO')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UlgKi0Rgosvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating points of original data and new generated img\n",
        "pts1 = np.float32([ [255, 60],[590, 60],[160, 380],[690, 380] ]) # 4 corners points of ORIGINAL image\n",
        "pts2 = np.float32([ [0,0],[width,0],[0,height],[width,height] ]) # 4 corners points of OUTPUT image\n",
        "\n",
        "matrix = cv2.getPerspectiveTransform(pts1,pts2) # getting perspective by 4 points of each image\n",
        "transformed = cv2.warpPerspective(frame, matrix, (width,height)) # warps perpective to new image"
      ],
      "metadata": {
        "id": "tYgZWboZostB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(frame)\n",
        "plt.title('first frame')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(transformed)\n",
        "plt.title('result of transformation')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YWWXwxd1ospy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_blur = cv2.GaussianBlur(transformed,(0,0),2) # blur applied\n",
        "blur_RGB = cv2.cvtColor(transformed_blur, cv2.COLOR_BGR2RGB) # rgb version\n",
        "\n",
        "# hsv colors of the snooker table\n",
        "lower = np.array([60, 200,150])\n",
        "upper = np.array([70, 255,240]) # HSV of snooker green: (60-70, 200-255, 150-240)\n",
        "\n",
        "hsv = cv2.cvtColor(blur_RGB, cv2.COLOR_RGB2HSV) # convert to hsv\n",
        "mask = cv2.inRange(hsv, lower, upper) # table's mask\n",
        "\n",
        "# apply closing\n",
        "kernel = np.ones((5,5),np.uint8)\n",
        "mask_closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel) # dilate->erode\n",
        "\n",
        "# invert mask to focus on objects on table\n",
        "_,mask_inv = cv2.threshold(mask_closing,5,255,cv2.THRESH_BINARY_INV) # mask inv\n",
        "\n",
        "masked_img = cv2.bitwise_and(transformed,transformed, mask=mask_inv) # masked image with inverted mask\n",
        "\n",
        "# plot edges, threshold, filter\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(transformed_blur)\n",
        "plt.title('blur')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(mask_closing)\n",
        "plt.title('table mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(masked_img)\n",
        "plt.title('masked objects')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4XZYCEufosm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find contours and filter them\n",
        "ctrs, hierarchy = cv2.findContours(mask_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # create contours in filtered img\n",
        "\n",
        "# draw contours before filter\n",
        "detected_objects = draw_rectangles(ctrs, transformed) # detected objects will be marked in boxes\n",
        "\n",
        "ctrs_filtered = filter_ctrs(ctrs) # filter unwanted contours (wrong size or shape)\n",
        "\n",
        "# draw contours after filter\n",
        "detected_objects_filtered = draw_rectangles(ctrs_filtered, transformed) # filtered detected objects will be marked in boxes\n",
        "\n",
        "# find average color inside contours:\n",
        "ctrs_color = find_ctrs_color(ctrs_filtered, transformed)\n",
        "ctrs_color = cv2.addWeighted(ctrs_color,0.5,transformed,0.5,0) # contours color image + transformed image\n",
        "\n",
        "# plot results\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(detected_objects)\n",
        "plt.title('detected objects on table')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(detected_objects_filtered)\n",
        "plt.title('filtered detected objects on table')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(ctrs_color)\n",
        "plt.title('calculate average inner color')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FgB_WmP-oskC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# design of the 2D generated table\n",
        "final = draw_balls(ctrs_filtered,img=transformed) # gets contours and draws balls in their centers\n",
        "final = draw_holes(final) # draws holes in the 2D img\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(frame)\n",
        "plt.title('original frame')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(final)\n",
        "plt.title('generated image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4vcGNWNLoshR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.imshow(frame2)\n",
        "plt.title('example #1')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sg3kGPploscR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame2_detect = find_balls(frame2) # find balls in frame2\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(frame2)\n",
        "plt.title('example #1')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(frame2_detect)\n",
        "plt.title('generated image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BlWOOtc3osZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.imshow(frame3)\n",
        "plt.title('example #2')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_J8yddvCosXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame3_detect = find_balls(frame3) # find balls in frame3\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(frame3)\n",
        "plt.title('example #2')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(frame3_detect)\n",
        "plt.title('generated image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ehu9b6Q9yX-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.imshow(frame4)\n",
        "plt.title('example #3')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D2DrszFHyX7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame4_detect = find_balls(frame4) # find balls in frame4\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(frame4)\n",
        "plt.title('example #3')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(frame4_detect)\n",
        "plt.title('generated image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UlR9XpAvyX5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new sizes (to keep it under 100mb)\n",
        "frame_zoom = frame[25:425,100:750] # zoom in on snooker table (resolution purposes)\n",
        "scale_percent = 78 # = percent of original size\n",
        "\n",
        "W = int((frame_zoom.shape[1] + (2 * width)) * scale_percent / 100) # final output width\n",
        "H = int((img.shape[0]) * scale_percent / 100) # final output height\n",
        "final_size = (W,H)\n",
        "\n",
        "N = 80 # for adding borders to image\n",
        "\n",
        "# for text (2 types)\n",
        "font_params = dict(org = (20,20),\n",
        "                   fontFace = cv2.FONT_HERSHEY_DUPLEX,\n",
        "                   fontScale = 0.7,\n",
        "                   color = (255,255,255), # white color\n",
        "                   lineType = 1)\n",
        "\n",
        "font_params2 = dict(org = (20,20),\n",
        "                   fontFace = cv2.FONT_HERSHEY_DUPLEX,\n",
        "                   fontScale = 0.7,\n",
        "                   color = (0,0,0), # black color\n",
        "                   lineType = 1)\n",
        "\n",
        "\n",
        "img = create_table() # creates green empty img to represent the 2D top view of the pool table\n",
        "frame_num = 0 # counting frames\n",
        "\n",
        "# video\n",
        "cap = cv2.VideoCapture('P6_Snooker.mp4')\n",
        "\n",
        "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT) # get total frames amount\n",
        "FPS = cap.get(cv2.CAP_PROP_FPS) # get FPS\n",
        "fourcc = cv2.VideoWriter_fourcc(*'avc1') # get codec\n",
        "out = cv2.VideoWriter('final_output_video.mp4',fourcc, FPS, final_size)\n",
        "\n",
        "# for output (switching image)\n",
        "flag_frames = [] # indexes of flag frames\n",
        "alpha = int(total_frames / 7)\n",
        "for i in range(7):\n",
        "    flag_frames.append(int(alpha*i%total_frames)) # takes 7 frames which will be flag frames for different images\n",
        "\n",
        "\n",
        "ret ,frameOld = cap.read()\n",
        "while(1):\n",
        "    ret ,frameNew = cap.read()\n",
        "    if ret == True:\n",
        "\n",
        "        # zoom + border\n",
        "        frame_zoom = frameNew[25:425,100:750] # zoom on table\n",
        "        frameNew_border = cv2.copyMakeBorder(frame_zoom, N, N, 0, 0, cv2.BORDER_CONSTANT) # add borders from top and bot\n",
        "\n",
        "        # warp perspective\n",
        "        matrix = cv2.getPerspectiveTransform(pts1,pts2) # getting perspective by both imgs points\n",
        "        transformed = cv2.warpPerspective(frameNew, matrix, (width,height)) # warps perpectivess\n",
        "\n",
        "        # blur\n",
        "        transformed_blur = cv2.GaussianBlur(transformed,(5,5),cv2.BORDER_DEFAULT) # blur applied\n",
        "\n",
        "        # mask\n",
        "        hsv = cv2.cvtColor(transformed_blur, cv2.COLOR_RGB2HSV) # convert to hsv\n",
        "        mask = cv2.inRange(hsv, lower, upper) # mask\n",
        "\n",
        "        # filter mask\n",
        "        kernel = np.ones((5,5),np.uint8)\n",
        "        mask_closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel) # dilate->erode\n",
        "        mask_rgb = cv2.cvtColor(mask_closing, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "\n",
        "        # apply threshold\n",
        "        ret,mask_inv = cv2.threshold(mask_closing,5,255,cv2.THRESH_BINARY_INV) # invert mask\n",
        "\n",
        "        # create image with masked objects on table\n",
        "        masked_img = cv2.bitwise_and(transformed,transformed, mask=mask_inv) # masked image\n",
        "\n",
        "        # find contours and filter them\n",
        "        ctrs, hierarchy = cv2.findContours(mask_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # find contours\n",
        "\n",
        "        ctrs_img = draw_rectangles(ctrs,transformed) # detected objects img for output\n",
        "\n",
        "        ctrs = filter_ctrs(ctrs) # filter contours by sizes and shapes\n",
        "\n",
        "        ctrs_filt_img = draw_rectangles(ctrs,transformed) # filtered objects img for output\n",
        "\n",
        "        ctrs_color = find_ctrs_color(ctrs,transformed) # image with colored contours\n",
        "        ctrs_color = cv2.addWeighted(ctrs_color,0.5,transformed,0.5,0) # contours color image + transformed image\n",
        "\n",
        "        # draw balls and holes\n",
        "        top_view = draw_balls(ctrs,radius=8,img=transformed) # draw filtered contours (balls)\n",
        "        top_view = draw_holes(top_view,color3=(0,140,200)) # (RGB=>BGR)\n",
        "\n",
        "        # adding text to output from previous steps of process\n",
        "        cv2.putText(frameNew_border,'input', **font_params)\n",
        "        cv2.putText(transformed,'warp perspective', **font_params)\n",
        "        cv2.putText(transformed_blur,'blur', **font_params)\n",
        "        cv2.putText(mask_rgb,'table mask', **font_params2)\n",
        "        cv2.putText(masked_img,'masked image', **font_params)\n",
        "        cv2.putText(ctrs_img,'detected objects', **font_params)\n",
        "        cv2.putText(ctrs_filt_img, 'filtered objects', **font_params)\n",
        "        cv2.putText(ctrs_color,'average inner color', **font_params)\n",
        "        cv2.putText(top_view, 'output', **font_params)\n",
        "\n",
        "        # use flag frames to switch output images:\n",
        "        # every X frames the output image is going to switch to another one\n",
        "        if (flag_frames[0] <= frame_num < flag_frames[1]):\n",
        "            changing = transformed # warp perspective\n",
        "        elif(flag_frames[1] < frame_num < flag_frames[2]):\n",
        "            changing = transformed_blur # blur\n",
        "        elif(flag_frames[2] < frame_num < flag_frames[3]):\n",
        "            changing = mask_rgb # mask\n",
        "        elif(flag_frames[3] < frame_num < flag_frames[4]):\n",
        "            changing = masked_img # masked img\n",
        "        elif(flag_frames[4] < frame_num < flag_frames[5]):\n",
        "            changing = ctrs_img # contours\n",
        "        elif(flag_frames[5] < frame_num < flag_frames[6]):\n",
        "            changing = ctrs_filt_img # filtered contours\n",
        "        elif(flag_frames[6] < frame_num):\n",
        "            changing = ctrs_color # colored contours\n",
        "\n",
        "        # concat and resize output\n",
        "        final = cv2.hconcat([frameNew_border, changing])\n",
        "        final = cv2.hconcat([final, top_view])\n",
        "        final = cv2.resize(final, final_size, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "        cv2.imshow('final',final)\n",
        "        out.write(final) # save final vid\n",
        "\n",
        "        frame_num += 1 # frame counter ++\n",
        "        k = cv2.waitKey(1) & 0xff\n",
        "        if k == 27:\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release() # release input video\n",
        "out.release() # release output video\n",
        "cv2.destroyAllWindows() # delete output window\n",
        "cv2.waitKey(1);"
      ],
      "metadata": {
        "id": "E-s58UJbyX2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hw5FngO0yXz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Crz0xOApyXxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tNENdksyXqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgfUTG_jyXoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57PwV-nOyXi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "039NFuoYyXcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MuFrHV2yXXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbNEsZxrosVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uqlh1esbosSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ccQtNBlyosQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install darkflow  # Install the darkflow library using pip\n",
        "\n",
        "import sys\n",
        "from darkflow.net.build import TFNet\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Configure YOLO\n",
        "options = {\n",
        "    \"model\": \"cfg/yolo_custom.cfg\",  # Path to your YOLO configuration file\n",
        "    \"load\": \"bin/yolo.weights\",  # Path to your YOLO weights file\n",
        "    \"train\": True,  # Set to True for training, False for inference\n",
        "    \"annotation\": \"./annotations/\",  # Path to your training annotations\n",
        "    \"dataset\": \"./images/\",  # Path to your training images\n",
        "    \"batch\": 8,  # Training batch size\n",
        "    \"epoch\": 100,  # Number of training epochs\n",
        "    \"threshold\": 0.5  # Confidence threshold for predictions\n",
        "}\n",
        "\n",
        "# Train the model (if train is True)\n",
        "if options[\"train\"]:\n",
        "    tfnet = TFNet(options)\n",
        "    tfnet.train()\n",
        "\n",
        "# Load the model for inference (if train is False or after training)\n",
        "tfnet = TFNet(options)  # Assuming you want to use the trained model\n",
        "\n",
        "# Test on a sample image\n",
        "test_image_path = './sample_video/test.jpg'  # Replace with your test image path\n",
        "image = cv2.imread(test_image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "results = tfnet.return_predict(image)\n",
        "\n",
        "# Visualize results\n",
        "for result in results:\n",
        "    top_left = (result['topleft']['x'], result['topleft']['y'])\n",
        "    bottom_right = (result['bottomright']['x'], result['bottomright']['y'])\n",
        "    label = result['label']\n",
        "    confidence = result['confidence']\n",
        "    image = cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)\n",
        "    image = cv2.putText(image, f\"{label} {confidence:.2f}\", top_left, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "# Show the results\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "piymHf7qDTLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GeJPGCAFC30S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3_MZ-lHC3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJoGrPGhC3up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQBNoGtlC3rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vk8C2apRC3pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBv-N5agC3lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Dependencies and Clone Darknet\n",
        "!apt-get update\n",
        "!apt-get install -y libopencv-dev\n",
        "!apt-get install -y wget unzip\n",
        "!pip install opencv-python\n",
        "# Clone Darknet repository\n",
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!make\n",
        "\n",
        "# Step 2: Download Pretrained YOLOv2 Weights\n",
        "!wget https://pjreddie.com/media/files/yolov2.weights -O yolov2.weights\n",
        "\n",
        "# Step 3: Set Up Custom Dataset\n",
        "# Create directories for dataset\n",
        "!mkdir -p data/ball/images data/ball/labels data/ball/train data/ball/valid data/ball/backup\n",
        "\n",
        "# Step 4: Unzip your custom dataset into the appropriate directories\n",
        "import zipfile\n",
        "\n",
        "dataset_path = \"/content/ball.zip\"  # Adjust if the dataset is in a different path\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/darknet/data/ball/\")\n",
        "\n",
        "# Organize images and labels into train and valid folders for Darknet\n",
        "import os\n",
        "train_images = '/content/darknet/data/ball/train/images/'\n",
        "valid_images = '/content/darknet/data/ball/valid/images/'\n",
        "train_labels = '/content/darknet/data/ball/train/labels/'\n",
        "valid_labels = '/content/darknet/data/ball/valid/labels/'\n",
        "\n",
        "# Create paths for train.txt and valid.txt files\n",
        "with open(\"/content/darknet/data/ball/train.txt\", \"w\") as f:\n",
        "    for img in os.listdir(train_images):\n",
        "        f.write(f\"data/ball/train/images/{img}\\n\")\n",
        "\n",
        "with open(\"/content/darknet/data/ball/valid.txt\", \"w\") as f:\n",
        "    for img in os.listdir(valid_images):\n",
        "        f.write(f\"data/ball/valid/images/{img}\\n\")\n",
        "\n",
        "# Step 5: Configure YOLO for Custom Training\n",
        "# 1. Modify yolov2.cfg for custom classes\n",
        "!cp cfg/yolov2.cfg cfg/yolov2_ball.cfg\n",
        "!sed -i 's/classes=80/classes=1/' cfg/yolov2_ball.cfg\n",
        "!sed -i 's/filters=425/filters=30/' cfg/yolov2_ball.cfg\n",
        "\n",
        "# 2. Modify obj.names and obj.data\n",
        "!echo \"ball\" > data/ball/obj.names\n",
        "!echo \"classes=1\" > data/ball/obj.data\n",
        "!echo \"train=data/ball/train.txt\" >> data/ball/obj.data\n",
        "!echo \"valid=data/ball/valid.txt\" >> data/ball/obj.data\n",
        "!echo \"names=data/ball/obj.names\" >> data/ball/obj.data\n",
        "!echo \"backup=data/ball/backup/\" >> data/ball/obj.data\n",
        "\n",
        "# Step 6: Train the YOLOv2 Model\n",
        "!./darknet detector train data/ball/obj.data cfg/yolov2_ball.cfg yolov2.weights -dont_show -map\n",
        "\n",
        "# Step 7: Test the Model on an Image\n",
        "# Make sure to replace 'test_image.jpg' with an actual test image from your dataset\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "test_image = '/content/darknet/data/ball/valid/images/test_image.jpg'  # Replace with an actual test image path\n",
        "!./darknet detector test data/ball/obj.data cfg/yolov2_ball.cfg data/yolov2_ball.weights {test_image} -thresh 0.25\n",
        "output_image = cv2.imread(\"predictions.jpg\")\n",
        "cv2_imshow(output_image)\n"
      ],
      "metadata": {
        "id": "d_n4L2p51EMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the darkflow repository\n",
        "!git clone https://github.com/thtrieu/darkflow.git\n",
        "\n",
        "# Navigate to the darkflow directory and install the package\n",
        "%cd darkflow\n",
        "!pip install -e .\n",
        "\n",
        "# Download YOLO weights (if not already present)\n",
        "!mkdir -p bin\n",
        "!wget https://pjreddie.com/media/files/yolov2.weights -O bin/yolo.weights\n",
        "\n",
        "# Import required libraries and define code for running YOLO with darkflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from darkflow.net.build import TFNet\n",
        "import cv2\n",
        "import pprint as pp\n",
        "\n",
        "# Configure YOLO model\n",
        "options = {\n",
        "    \"model\": \"cfg/yolo_custom.cfg\",\n",
        "    \"load\": \"bin/yolo.weights\",\n",
        "    \"batch\": 8,\n",
        "    \"epoch\": 100,\n",
        "    \"gpu\": 1.0,\n",
        "    \"train\": True,\n",
        "    \"annotation\": \"./annotations/\",\n",
        "    \"dataset\": \"./images/\"\n",
        "}\n",
        "tfnet = TFNet(options)\n",
        "tfnet.train()\n",
        "\n",
        "# Save the model to a protobuf file (optional)\n",
        "tfnet.savepb()\n",
        "\n",
        "# Load the trained model for predictions\n",
        "options = {\n",
        "    \"model\": \"cfg/yolo_custom.cfg\",\n",
        "    \"load\": -1,\n",
        "    \"gpu\": 1.0\n",
        "}\n",
        "tfnet2 = TFNet(options)\n",
        "tfnet2.load_from_ckpt()\n",
        "\n",
        "# Test on an image\n",
        "original_img = cv2.imread(\"sample_img/test_image1.jpg\")\n",
        "original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "results = tfnet2.return_predict(original_img)\n",
        "print(results)\n",
        "\n",
        "# Display image with bounding boxes\n",
        "fig, ax = plt.subplots(figsize=(15, 15))\n",
        "ax.imshow(original_img)\n",
        "\n",
        "# Function to draw bounding boxes\n",
        "def boxing(original_img, predictions):\n",
        "    new_image = np.copy(original_img)\n",
        "    for result in predictions:\n",
        "        top_x = result['topleft']['x']\n",
        "        top_y = result['topleft']['y']\n",
        "        btm_x = result['bottomright']['x']\n",
        "        btm_y = result['bottomright']['y']\n",
        "        confidence = result['confidence']\n",
        "        label = f\"{result['label']} {round(confidence, 3)}\"\n",
        "\n",
        "        if confidence > 0.3:\n",
        "            new_image = cv2.rectangle(new_image, (top_x, top_y), (btm_x, btm_y), (255, 0, 0), 3)\n",
        "            new_image = cv2.putText(new_image, label, (top_x, top_y - 5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0, 230, 0), 1, cv2.LINE_AA)\n",
        "    return new_image\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "ax.imshow(boxing(original_img, results))\n",
        "\n",
        "# Video Processing with YOLO\n",
        "cap = cv2.VideoCapture('./sample_video/test_video.avi')\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "out = cv2.VideoWriter('./sample_video/output.avi', fourcc, 20.0, (width, height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame = np.asarray(frame)\n",
        "    results = tfnet2.return_predict(frame)\n",
        "    new_frame = boxing(frame, results)\n",
        "    out.write(new_frame)\n",
        "    cv2.imshow('frame', new_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "aV9YCIDgAmRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clone Darknet repository\n",
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "%cd darknet\n",
        "\n",
        "# Step 2: Install dependencies\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile  # Enable OpenCV\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile        # Enable GPU (if available)\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile    # Enable cuDNN\n",
        "!make\n",
        "\n",
        "# Step 3: Download YOLOv2 weights\n",
        "!wget https://pjreddie.com/media/files/yolov2.weights -O yolov2.weights\n",
        "\n",
        "# Step 4: Unzip the dataset\n",
        "import zipfile\n",
        "\n",
        "dataset_path = '/content/ball.zip'  # Path to your zip file\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/darknet/data/ball')\n",
        "\n",
        "# Step 5: Configure YOLO for Single-Class Detection\n",
        "# Copy and modify the YOLO configuration file\n",
        "!cp cfg/yolov2.cfg cfg/yolov2_ball.cfg\n",
        "!sed -i 's/classes=80/classes=1/' cfg/yolov2_ball.cfg\n",
        "!sed -i 's/filters=425/filters=30/' cfg/yolov2_ball.cfg\n",
        "\n",
        "# Create a custom labels file\n",
        "with open(\"data/ball/obj.names\", \"w\") as f:\n",
        "    f.write(\"ball\\n\")\n",
        "\n",
        "# Update the data file\n",
        "with open(\"data/ball/obj.data\", \"w\") as f:\n",
        "    f.write(\"classes = 1\\n\")\n",
        "    f.write(\"train = data/ball/train.txt\\n\")\n",
        "    f.write(\"valid = data/ball/valid.txt\\n\")\n",
        "    f.write(\"names = data/ball/obj.names\\n\")\n",
        "    f.write(\"backup = backup/\")\n",
        "\n",
        "# Prepare train.txt and valid.txt files\n",
        "import os\n",
        "\n",
        "train_path = '/content/darknet/data/ball/train/images'\n",
        "valid_path = '/content/darknet/data/ball/valid/images'\n",
        "\n",
        "# Create train.txt\n",
        "with open(\"data/ball/train.txt\", \"w\") as f:\n",
        "    for img in os.listdir(train_path):\n",
        "        f.write(f\"data/ball/train/images/{img}\\n\")\n",
        "\n",
        "# Create valid.txt\n",
        "with open(\"data/ball/valid.txt\", \"w\") as f:\n",
        "    for img in os.listdir(valid_path):\n",
        "        f.write(f\"data/ball/valid/images/{img}\\n\")\n",
        "\n",
        "# Step 6: Start Training\n",
        "!./darknet detector train data/ball/obj.data cfg/yolov2_ball.cfg yolov2.weights -dont_show -map\n",
        "\n",
        "# Step 7: Testing on Images\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_and_plot(image_path):\n",
        "    result = !./darknet detector test data/ball/obj.data cfg/yolov2_ball.cfg backup/yolov2_ball_final.weights {image_path} -thresh 0.25\n",
        "    image = cv2.imread(\"predictions.jpg\")\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage: predict on a single test image\n",
        "predict_and_plot('/content/darknet/data/ball/test/images/sample.jpg')\n",
        "\n",
        "# Step 8: Testing on Video\n",
        "def predict_on_video(video_path, output_path=\"output.avi\"):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        cv2.imwrite(\"temp_frame.jpg\", frame)\n",
        "        result = !./darknet detector test data/ball/obj.data cfg/yolov2_ball.cfg backup/yolov2_ball_final.weights temp_frame.jpg -thresh 0.25\n",
        "        prediction = cv2.imread(\"predictions.jpg\")\n",
        "        out.write(prediction)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "# Run on a sample video\n",
        "predict_on_video('/content/darknet/data/ball/test/sample_video.mp4')\n"
      ],
      "metadata": {
        "id": "fue2yCq3-0pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Directory where test images are located\n",
        "test_images_dir = '/content/darknet/data/ball/test/images'\n",
        "\n",
        "# Define a function to predict and display results on all test images\n",
        "def predict_and_plot_all(directory):\n",
        "    for img_file in os.listdir(directory):\n",
        "        if img_file.endswith(('.jpg', '.png')):\n",
        "            img_path = os.path.join(directory, img_file)\n",
        "\n",
        "            # Run prediction on the current image\n",
        "            result = !./darknet detector test data/ball/obj.data cfg/yolov2_ball.cfg backup/yolov2_ball_final.weights {img_path} -thresh 0.25\n",
        "\n",
        "            # Load and display the prediction\n",
        "            prediction_image = cv2.imread(\"predictions.jpg\")\n",
        "            plt.figure(figsize=(8, 8))\n",
        "            plt.imshow(cv2.cvtColor(prediction_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(f\"Prediction for {img_file}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "# Run predictions and display results for all test images\n",
        "predict_and_plot_all(test_images_dir)\n"
      ],
      "metadata": {
        "id": "eFstZ3EF_8fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from darkflow.net.build import TFNet\n",
        "import cv2\n",
        "import pprint as pp\n",
        "from math import ceil\n",
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "# Set options for training YOLO\n",
        "options = {\n",
        "    \"model\": \"cfg/yolo_custom.cfg\",\n",
        "    \"load\": \"bin/yolo.weights\",\n",
        "    \"batch\": 8,\n",
        "    \"epoch\": 100,\n",
        "    \"gpu\": 1.0,\n",
        "    \"train\": True,\n",
        "    \"annotation\": \"./annotations/\",\n",
        "    \"dataset\": \"./images/\"\n",
        "}\n",
        "\n",
        "# Initialize and train YOLO model\n",
        "tfnet = TFNet(options)\n",
        "tfnet.train()\n",
        "\n",
        "# Save model to protobuf file (.pb) (optional)\n",
        "tfnet.savepb()\n",
        "\n",
        "# Set options for loading trained YOLO model\n",
        "options = {\n",
        "    \"model\": \"cfg/yolo_custom.cfg\",\n",
        "    \"load\": -1,\n",
        "    \"gpu\": 1.0\n",
        "}\n",
        "\n",
        "# Load YOLO model for inference\n",
        "tfnet2 = TFNet(options)\n",
        "tfnet2.load_from_ckpt()\n",
        "\n",
        "# Read and display an image\n",
        "original_img = cv2.imread(\"sample_img/test_image1.jpg\")\n",
        "original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "results = tfnet2.return_predict(original_img)\n",
        "print(results)\n",
        "\n",
        "# Display original image with matplotlib\n",
        "fig, ax = plt.subplots(figsize=(15, 15))\n",
        "ax.imshow(original_img)\n",
        "\n",
        "# Function for drawing bounding boxes on predictions\n",
        "def boxing(original_img, predictions):\n",
        "    newImage = np.copy(original_img)\n",
        "    for result in predictions:\n",
        "        top_x = result['topleft']['x']\n",
        "        top_y = result['topleft']['y']\n",
        "        btm_x = result['bottomright']['x']\n",
        "        btm_y = result['bottomright']['y']\n",
        "        confidence = result['confidence']\n",
        "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
        "\n",
        "        if confidence > 0.3:\n",
        "            newImage = cv2.rectangle(newImage, (top_x, top_y), (btm_x, btm_y), (255, 0, 0), 3)\n",
        "            newImage = cv2.putText(newImage, label, (top_x, top_y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0, 230, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    return newImage\n",
        "\n",
        "# Display boxed image\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "ax.imshow(boxing(original_img, results))\n",
        "\n",
        "# Process multiple images in a grid layout\n",
        "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
        "for i in range(5):\n",
        "    original_img = cv2.imread(\"sample_img/test_image\" + str(i+1) + \".jpg\")\n",
        "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "    results = tfnet2.return_predict(original_img)\n",
        "    ax[ceil(i/3)-1, i%3].imshow(boxing(original_img, results))\n",
        "\n",
        "# Process video for object detection\n",
        "cap = cv2.VideoCapture('./sample_video/test_video.avi')\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "out = cv2.VideoWriter('./sample_video/output.avi', fourcc, 20.0, (int(width), int(height)))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        frame = np.asarray(frame)\n",
        "        results = tfnet2.return_predict(frame)\n",
        "        new_frame = boxing(frame, results)\n",
        "        out.write(new_frame)\n",
        "        cv2.imshow('frame', new_frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Display YouTube video in notebook\n",
        "YouTubeVideo('1MwIVcni0P4')\n"
      ],
      "metadata": {
        "id": "p_Rvuvc3_oGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install darkflow # Install the darkflow library using pip (global installation)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ODGUM4SSEbEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load YOLOv2 network with weights and config files\n",
        "weights_path = 'yolov2-ball.weights'  # Replace with the path to your YOLOv2 weights\n",
        "config_path = 'yolov2-ball.cfg'       # Replace with the path to your YOLOv2 config file\n",
        "net = cv2.dnn.readNet(weights_path, config_path)\n",
        "\n",
        "# Set backend and target for optimization (if using GPU)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)  # Use DNN_TARGET_CUDA if GPU is available\n",
        "\n",
        "# Load class names (if available, typically for custom model there is only one class 'ball')\n",
        "classes = [\"ball\"]  # This can be replaced with actual class names if using multiple classes\n",
        "\n",
        "def detect_ball(image):\n",
        "    # Preprocess image for YOLOv2\n",
        "    blob = cv2.dnn.blobFromImage(image, scalefactor=1/255.0, size=(416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    layer_names = net.getLayerNames()\n",
        "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    # Run forward pass and gather detections\n",
        "    detections = net.forward(output_layers)\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "\n",
        "    # Loop over detections\n",
        "    for output in detections:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            # Filter for cricket ball class with confidence threshold\n",
        "            if confidence > 0.5:  # Adjust threshold as needed\n",
        "                box = detection[0:4] * np.array([w, h, w, h])\n",
        "                (center_x, center_y, width, height) = box.astype(\"int\")\n",
        "\n",
        "                # Calculate bounding box coordinates\n",
        "                x = int(center_x - (width / 2))\n",
        "                y = int(center_y - (height / 2))\n",
        "\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply Non-Maximum Suppression to filter overlapping boxes\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)\n",
        "\n",
        "    # Draw bounding boxes and labels on the image\n",
        "    for i in indices.flatten():\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = str(classes[class_ids[i]])\n",
        "        confidence = confidences[i]\n",
        "        color = (0, 255, 0)  # Color for the bounding box\n",
        "\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(image, f\"{label} {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Path to your input video file (replace with actual path)\n",
        "video_path = 'path/to/your/cricket_video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Output video file (optional)\n",
        "output_path = 'output_cricket_ball_detection.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = None\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Detect balls in the frame\n",
        "    output_frame = detect_ball(frame)\n",
        "\n",
        "    # Initialize video writer if not yet created\n",
        "    if out is None:\n",
        "        height, width = output_frame.shape[:2]\n",
        "        out = cv2.VideoWriter(output_path, fourcc, 30, (width, height))\n",
        "\n",
        "    # Write frame to output file and display\n",
        "    out.write(output_frame)\n",
        "    cv2.imshow('Ball Detection', output_frame)\n",
        "\n",
        "    # Press 'q' to exit early\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "LvczbYpAEe92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/Screenshot 2024-11-12 121817.png'  # Replace with your image path\n",
        "image = cv.imread(image_path)\n",
        "\n",
        "# Check if the image is loaded successfully\n",
        "if image is None:\n",
        "    print(\"Could not open or find the image.\")\n",
        "    exit()\n",
        "\n",
        "# Convert to grayscale\n",
        "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise and improve circle detection\n",
        "blurred_image = cv.GaussianBlur(gray_image, (17, 17), 0)\n",
        "\n",
        "# Detect circles using Hough Circle Transform\n",
        "circles = cv.HoughCircles(\n",
        "    blurred_image,\n",
        "    cv.HOUGH_GRADIENT,\n",
        "    dp=1.2,\n",
        "    minDist=100,\n",
        "    param1=100,\n",
        "    param2=30,\n",
        "    minRadius=75,\n",
        "    maxRadius=400\n",
        ")\n",
        "\n",
        "# Check if any circles were detected\n",
        "if circles is not None:\n",
        "    circles = np.uint16(np.around(circles))  # Convert coordinates to integers\n",
        "    for i in circles[0, :]:\n",
        "        # Draw the outer circle\n",
        "        cv.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 3)\n",
        "        # Draw the center of the circle\n",
        "        cv.circle(image, (i[0], i[1]), 5, (0, 0, 255), 3)\n",
        "\n",
        "# Show the result\n",
        "cv.imshow(\"Detected Ball\", image)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "owqatyhWIE-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow # Import the cv2_imshow patch from google.colab.patches\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/Screenshot 2024-11-12 121817."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Yh3ZPgeYIupl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5qur9I8xIy2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from __future__ import print_function, division\n",
        "%matplotlib inline\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "import torchvision.transforms.functional as f\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.stats import multivariate_normal\n",
        "import time\n",
        "import os\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import pandas as pd\n",
        "import skimage\n",
        "from skimage import io, transform, img_as_ubyte\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "t.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "# SweatyNet-1 Model\n",
        "\n",
        "class SweatyModel1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SweatyModel1,self).__init__()\n",
        "\n",
        "        # batch x 640 x 512\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=3//2),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # batch x 320 x 256\n",
        "        self.pooling1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        #concat1 = (maxpool1 + layer2) -> 8 + 16 = 24\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(24, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        #concat2 = (maxpool2 + layer3) -> 24 + 32 = 56\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        self.pooling3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(56, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        #concat3 = (maxpool3 + layer4) -> 56 + 64 = 120\n",
        "\n",
        "        # batch x 40 x 32\n",
        "        self.pooling4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(120, 128, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        #concat4 = (concat3 + upsample1) -> 120 + 64 = 184\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(184, 64, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        #concat5 = (concat2 + upsample2) -> 56 + 32 = 88\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(88, 16, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 1, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "def forward(self, x):\n",
        "\n",
        "        # batch x 640 x 512\n",
        "        layer_out1 = self.layer1(x)\n",
        "\n",
        "        # batch x 320 x 256\n",
        "        pool_out1 = self.pooling1(layer_out1)\n",
        "        layer_out2 = self.layer2(pool_out1)\n",
        "        concat_out1 = t.cat((pool_out1, layer_out2), dim=1)\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        pool_out2 = self.pooling2(concat_out1)\n",
        "        layer_out3 = self.layer3(pool_out2)\n",
        "        concat_out2 = t.cat((pool_out2, layer_out3), dim=1)\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        pool_out3 = self.pooling3(concat_out2)\n",
        "        layer_out4 = self.layer4(pool_out3)\n",
        "        concat_out3 = t.cat((pool_out3, layer_out4), dim=1)\n",
        "\n",
        "        # batch x 40 x 32\n",
        "        pool_out4 = self.pooling4(concat_out3)\n",
        "        layer_out5 = self.layer5(pool_out4)\n",
        "        upsample_out1 = func.interpolate(layer_out5, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        concat_out4 = t.cat((concat_out3, upsample_out1), dim=1)\n",
        "        layer_out6 = self.layer6(concat_out4)\n",
        "        upsample_out2 = func.interpolate(layer_out6, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        concat_out5 = t.cat((concat_out2, upsample_out2), dim=1)\n",
        "        out = self.layer7(concat_out5)\n",
        "\n",
        "        return out\n",
        "\n",
        "# SweatyNet-2 Model\n",
        "\n",
        "class SweatyModel2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SweatyModel2,self).__init__()\n",
        "\n",
        "        # batch x 640 x 512\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=3//2),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # batch x 320 x 256\n",
        "        self.pooling1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "\n",
        "        )\n",
        "        #concat1 = (maxpool1 + layer2) -> 8 + 16 = 24\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(24, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "\n",
        "        )\n",
        "        #concat2 = (maxpool2 + layer3) -> 24 + 32 = 56\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        self.pooling3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(56, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "\n",
        "        )\n",
        "        #concat3 = (maxpool3 + layer4) -> 56 + 64 = 120\n",
        "\n",
        "        # batch x 40 x 32\n",
        "        self.pooling4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(120, 128, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        #concat4 = (concat3 + upsample1) -> 120 + 64 = 184\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(184, 64, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        #concat5 = (concat2 + upsample2) -> 56 + 32 = 88\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(88, 16, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 1, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # batch x 640 x 512\n",
        "        layer_out1 = self.layer1(x)\n",
        "\n",
        "        # batch x 320 x 256\n",
        "        pool_out1 = self.pooling1(layer_out1)\n",
        "        layer_out2 = self.layer2(pool_out1)\n",
        "        concat_out1 = t.cat((pool_out1, layer_out2), dim=1)\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        pool_out2 = self.pooling2(concat_out1)\n",
        "        layer_out3 = self.layer3(pool_out2)\n",
        "        concat_out2 = t.cat((pool_out2, layer_out3), dim=1)\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        pool_out3 = self.pooling3(concat_out2)\n",
        "        layer_out4 = self.layer4(pool_out3)\n",
        "        concat_out3 = t.cat((pool_out3, layer_out4), dim=1)\n",
        "\n",
        "        # batch x 40 x 32\n",
        "        pool_out4 = self.pooling4(concat_out3)\n",
        "        layer_out5 = self.layer5(pool_out4)\n",
        "        upsample_out1 = func.interpolate(layer_out5, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        concat_out4 = t.cat((concat_out3, upsample_out1), dim=1)\n",
        "        layer_out6 = self.layer6(concat_out4)\n",
        "        upsample_out2 = func.interpolate(layer_out6, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        concat_out5 = t.cat((concat_out2, upsample_out2), dim=1)\n",
        "        out = self.layer7(concat_out5)\n",
        "\n",
        "        return out\n",
        "\n",
        "# SweatyNet-3 Model\n",
        "\n",
        "class SweatyModel3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SweatyModel3,self).__init__()\n",
        "\n",
        "        # batch x 640 x 512\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=3//2),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # batch x 320 x 256\n",
        "        self.pooling1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 8, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(8, 16, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        #concat1 = (maxpool1 + layer2) -> 8 + 16 = 24\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(24, 16, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        #concat2 = (maxpool2 + layer3) -> 24 + 32 = 56\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        self.pooling3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(56, 32, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 32, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        #concat3 = (maxpool3 + layer4) -> 56 + 64 = 120\n",
        "\n",
        "        # batch x 40 x 32\n",
        "        self.pooling4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(120, 64, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 64, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 64, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        #concat4 = (concat3 + upsample1) -> 120 + 64 = 184\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(184, 64, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 32, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        #concat5 = (concat2 + upsample2) -> 56 + 32 = 88\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(88, 16, 1, padding=1//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 1, 3, padding=3//2),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # batch x 640 x 512\n",
        "        layer_out1 = self.layer1(x)\n",
        "\n",
        "        # batch x 320 x 256\n",
        "        pool_out1 = self.pooling1(layer_out1)\n",
        "        layer_out2 = self.layer2(pool_out1)\n",
        "        concat_out1 = t.cat((pool_out1, layer_out2), dim=1)\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        pool_out2 = self.pooling2(concat_out1)\n",
        "        layer_out3 = self.layer3(pool_out2)\n",
        "        concat_out2 = t.cat((pool_out2, layer_out3), dim=1)\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        pool_out3 = self.pooling3(concat_out2)\n",
        "        layer_out4 = self.layer4(pool_out3)\n",
        "        concat_out3 = t.cat((pool_out3, layer_out4), dim=1)\n",
        "\n",
        "        # batch x 40 x 32\n",
        "        pool_out4 = self.pooling4(concat_out3)\n",
        "        layer_out5 = self.layer5(pool_out4)\n",
        "        upsample_out1 = func.interpolate(layer_out5, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        # batch x 80 x 64\n",
        "        concat_out4 = t.cat((concat_out3, upsample_out1), dim=1)\n",
        "        layer_out6 = self.layer6(concat_out4)\n",
        "        upsample_out2 = func.interpolate(layer_out6, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        # batch x 160 x 128\n",
        "        concat_out5 = t.cat((concat_out2, upsample_out2), dim=1)\n",
        "        out = self.layer7(concat_out5)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Custom ToTensor\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, labels = sample['image'], sample['labels']\n",
        "\n",
        "        # swap color axis\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "\n",
        "        image = image.permute(2, 0, 1)\n",
        "        image = image.ToTensor()\n",
        "\n",
        "        return {'image': image,\n",
        "                'labels': labels}\n",
        "\n",
        "\n",
        "# Custom Rescale\n",
        "\n",
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, height, width):\n",
        "        self.new_h = height\n",
        "        self.new_w = width\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, labels = sample['image'], sample['labels']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "\n",
        "        new_h, new_w = int(self.new_h), int(self.new_w)\n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "\n",
        "        return {'image': img, 'labels': labels}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Creation of Custom Dataset and transforms\n",
        "\n",
        "class SoccerBallDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, annotation_path, transformation=None):\n",
        "\n",
        "        self.target = []\n",
        "        self.root_dir = root_dir\n",
        "        self.annotation_path = annotation_path\n",
        "        self.transformation = transformation\n",
        "        self.annotations_frame = pd.read_csv(self.annotation_path)\n",
        "\n",
        "        for index, rows in self.annotations_frame.iterrows():\n",
        "          img_name, width, height, x1, y1, x2, y2, c_x, c_y, w, h = rows\n",
        "\n",
        "          x1 = x1 / 4\n",
        "          x2 = x2 / 4\n",
        "          y1 = y1 / 4\n",
        "          y2 = y2 / 4\n",
        "          x = (x1 + x2) / 2\n",
        "          y = (y1 + y2) / 2\n",
        "\n",
        "          center =(x,y)\n",
        "          var = 6\n",
        "\n",
        "          matrix = np.zeros((128,160))\n",
        "\n",
        "          if (x>0 and y>0):\n",
        "            for i in range(int(x1), int(x2)):\n",
        "              for j in range(int(y1), int(y2)):\n",
        "                matrix[j,i] = 100*multivariate_normal.pdf([i,j], center, [var,var])\n",
        "\n",
        "\n",
        "          self.target.append(matrix)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.annotations_frame.iloc[idx, 0])\n",
        "        image = io.imread(img_name)\n",
        "\n",
        "        sample = {'image': t.from_numpy(image), 'labels': t.from_numpy(self.target[idx]).unsqueeze(-1)}\n",
        "\n",
        "        if self.transformation:\n",
        "            sample = self.transformation(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "\n",
        "class Sweaty_ModelEvaluator:\n",
        "\n",
        "    def __init__(self, model_path, val_images_path, test_images_path, num_epochs):\n",
        "      self.model_path = model_path\n",
        "      self.val_images_path = val_images_path\n",
        "      self.test_images_path = test_images_path\n",
        "      self.num_epochs = num_epochs\n",
        "\n",
        "    # Creating and loading the train and test dataset\n",
        "    def data_loading(self, root_dir, annotation_path, batch_size, shuffle):\n",
        "      transformed_dataset = SoccerBallDataset(root_dir,\n",
        "                                              annotation_path,\n",
        "                                              transformation=transforms.Compose([\n",
        "                                                  Rescale(512, 640)\n",
        "                                              ]))\n",
        "\n",
        "      dataset_loader = t.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,\n",
        "                                               shuffle=shuffle, num_workers=4, drop_last=True)\n",
        "\n",
        "      return dataset_loader\n",
        "\n",
        "\n",
        "    # Training the model\n",
        "    def train_model(self, model, train_loader):\n",
        "        epoch_loss = []\n",
        "        train_loss_list = []\n",
        "        train_output = []\n",
        "        predicted = 0.0\n",
        "        train_label_size = 0\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for i, batch in enumerate(train_loader):\n",
        "                batch_images = batch['image'].permute(0,3,1,2)\n",
        "                batch_labels = batch['labels'].permute(0,3,1,2)\n",
        "\n",
        "                batch_images = batch_images/255\n",
        "\n",
        "                if t.cuda.is_available():\n",
        "                  batch_images = batch_images.cuda().float()\n",
        "                  batch_labels = batch_labels.cuda().float()\n",
        "                else:\n",
        "                  batch_images = batch_images\n",
        "                  batch_labels = batch_labels\n",
        "\n",
        "                # Clearing the gradients\n",
        "                sweaty_optimizer.zero_grad()\n",
        "\n",
        "                # Passing the image dataset to the Sweaty model\n",
        "                output = model(batch_images)\n",
        "                train_output.append(output)\n",
        "\n",
        "                # Calculating the Loss(MSE)\n",
        "                train_loss = sweaty_criterion(output, batch_labels)\n",
        "\n",
        "                # Getting the gradients\n",
        "                train_loss.backward()\n",
        "\n",
        "                # Updating the parameters\n",
        "                sweaty_optimizer.step()\n",
        "\n",
        "                train_loss_list.append(train_loss)\n",
        "                running_loss += train_loss.data\n",
        "\n",
        "                train_label_size += batch_labels.size(0)\n",
        "\n",
        "            # Calculate train loss and accuracy\n",
        "            epoch_loss = running_loss / train_label_size\n",
        "            print('Epoch {}/{}\\t - Loss: {:.8f}'.format(epoch+1, self.num_epochs, epoch_loss.data))\n",
        "\n",
        "            if epoch % 5 == 0:\n",
        "              t.save(sweaty_model.state_dict(), self.model_path+'sweatynet1_trained_epoch_'+str(epoch)+'.pkl')\n",
        "\n",
        "        return model, train_loss_list, train_output\n",
        "\n",
        "\n",
        "    # Validating the model\n",
        "    def validation_model(self, model, val_loader):\n",
        "        epoch_loss = []\n",
        "        val_output = []\n",
        "        val_loss_list = []\n",
        "\n",
        "        # Iterate through validation dataset\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            batch_images = batch['image'].permute(0,3,1,2)\n",
        "            batch_labels = batch['labels'].permute(0,3,1,2)\n",
        "\n",
        "            batch_images = batch_images/255\n",
        "\n",
        "            if t.cuda.is_available():\n",
        "              batch_images = batch_images.cuda().float()\n",
        "              batch_labels = batch_labels.cuda().float()\n",
        "            else:\n",
        "              batch_images = batch_images\n",
        "              batch_labels = batch_labels\n",
        "\n",
        "            # Output from the model\n",
        "            voutput = model(batch_images)\n",
        "            val_output.append(voutput)\n",
        "\n",
        "            # Finding the validation loss\n",
        "            val_loss = sweaty_criterion(voutput, batch_labels)\n",
        "\n",
        "            val_loss_list.append(val_loss)\n",
        "\n",
        "            target_img = self.val_images_path+'sweaty1_val_target'+str(i)+'.png'\n",
        "            output_img = self.val_images_path+'sweaty1_val_output'+str(i)+'.png'\n",
        "\n",
        "            if i % 5 == 0:\n",
        "              for j in range(1):\n",
        "                print('#',i)\n",
        "                self.visualize_output((batch_labels[j].reshape(1,128,160)).cpu().detach().numpy(), 'Target')\n",
        "                #plt.imshow((batch_images[j].reshape(3,512,640)).cpu().detach().numpy())\n",
        "                self.visualize_output((voutput[j]).cpu().detach().numpy(), 'Output')\n",
        "                #torchvision.utils.save_image(batch_labels[j], target_img)\n",
        "                #torchvision.utils.save_image(voutput[j], output_img)\n",
        "\n",
        "        return val_output, val_loss_list\n",
        "\n",
        "\n",
        "    # Testing the model\n",
        "    def test_model(self, model, test_loader):\n",
        "        epoch_loss = []\n",
        "        test_output = []\n",
        "        test_loss_list = []\n",
        "\n",
        "        # Iterate through test dataset\n",
        "        for i, batch in enumerate(test_loader):\n",
        "            batch_images = batch['image'].permute(0,3,1,2)\n",
        "            batch_labels = batch['labels'].permute(0,3,1,2)\n",
        "\n",
        "            batch_images = batch_images/255\n",
        "\n",
        "            if t.cuda.is_available():\n",
        "              batch_images = batch_images.cuda().float()\n",
        "              batch_labels = batch_labels.cuda().float()\n",
        "            else:\n",
        "              batch_images = batch_images\n",
        "              batch_labels = batch_labels\n",
        "\n",
        "            # Output from the model\n",
        "            outputs = model(batch_images)\n",
        "            test_output.append(outputs)\n",
        "\n",
        "            # Finding the test loss\n",
        "            test_loss = sweaty_criterion(outputs, batch_labels)\n",
        "\n",
        "            test_loss_list.append(test_loss)\n",
        "\n",
        "            target_img = self.test_images_path+'sweaty1_test_target_'+str(i)+'.png'\n",
        "            output_img = self.test_images_path+'sweaty1_test_output_'+str(i)+'.png'\n",
        "\n",
        "            if 1:\n",
        "              for j in range(1):\n",
        "                print('\\n#Frame',i)\n",
        "                torchvision.utils.save_image(batch_labels[j], target_img)\n",
        "                torchvision.utils.save_image(outputs[j], output_img)\n",
        "                if i % 5 == 0:\n",
        "                  self.visualize_output((batch_labels[j].reshape(1,128,160)).cpu().detach().numpy(), 'Target')\n",
        "                  #plt.imshow((batch_images[j].reshape(3,512,640)).cpu().detach().numpy())\n",
        "                  self.visualize_output((outputs[j]).cpu().detach().numpy(), 'Output')\n",
        "\n",
        "                j+=1\n",
        "\n",
        "        return test_output, test_loss_list\n",
        "\n",
        "    # Plotting the loss\n",
        "    def plot_loss(self, loss, save_dir):\n",
        "\n",
        "        plt.clf()\n",
        "\n",
        "        iterations = range(1, len(loss)+1)\n",
        "        plt.title('Loss')\n",
        "        plt.plot(iterations, loss, color = 'b')\n",
        "        plt.xlabel('Number of iterations')\n",
        "        plt.ylabel('Loss')\n",
        "\n",
        "        plt.savefig(save_dir)\n",
        "        plt.clf()\n",
        "\n",
        "    # Visualizing the output\n",
        "    def visualize_output(self, out, title='None'):\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        for i in range(1):\n",
        "            plt.subplot(6,6,i+1)\n",
        "            #plt.xticks([])\n",
        "            #plt.yticks([])\n",
        "            plt.axes()\n",
        "            plt.grid(False)\n",
        "            plt.Text('Heading')\n",
        "            plt.title(title)\n",
        "            plt.imshow(out[i], cmap = 'gray')\n",
        "            #plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "target_coordinate_list=[]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PostProcessing:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.list_maximal_values_batches = []\n",
        "\n",
        "    # Creating the test coordinates list of the ball\n",
        "    def get_coordinates(self, annotation_path):\n",
        "\n",
        "        target_coordinates = []\n",
        "        annotations_frame = pd.read_csv(annotation_path)\n",
        "\n",
        "        for index, rows in annotations_frame.iterrows():\n",
        "          _, _, _, x1, y1, x2, y2, _, _, _, _ = rows\n",
        "\n",
        "          x1 = x1 / 4\n",
        "          x2 = x2 / 4\n",
        "          y1 = y1 / 4\n",
        "          y2 = y2 / 4\n",
        "          x = (x1 + x2) / 2\n",
        "          y = (y1 + y2) / 2\n",
        "          center = (x,y)\n",
        "          target_coordinates.append(center)\n",
        "\n",
        "        return target_coordinates\n",
        "\n",
        "    def erosion(self, output_list):\n",
        "        erosion_list = []\n",
        "        #img = cv2.imread('j.png',0)\n",
        "        kernel = np.ones((4,4),np.uint8)\n",
        "\n",
        "        for i in range(0, len(output_list)):\n",
        "          out = (output_list[i].reshape(1,128,160)).cpu().detach().numpy()\n",
        "\n",
        "          erosion_output = cv2.erode(out, kernel, iterations = 1)\n",
        "          erosion_list.append(erosion_output)\n",
        "\n",
        "        return erosion_list\n",
        "        #return output_list\n",
        "\n",
        "\n",
        "    def findmaximal(self, test_output_matrix_image, target_center_coordinates):\n",
        "\n",
        "      z=test_output_matrix_image.permute(1,2,0)\n",
        "      z=test_output_matrix_image\n",
        "      z.to(dtype=t.float32)\n",
        "      list_with_more_contours=[]\n",
        "      internal_list_distance=[]\n",
        "\n",
        "      center_coord_targ=target_center_coordinates\n",
        "      number=np.count_nonzero(z.cpu().detach().numpy())\n",
        "      if(number>0):\n",
        "\n",
        "        prob_map=z.cpu().detach().numpy()\n",
        "        prob_map = np.squeeze(prob_map)\n",
        "        maximum_value=np.amax(prob_map)\n",
        "        thresh=0.7*maximum_value\n",
        "        bin_map = prob_map > thresh\n",
        "        bin_img = img_as_ubyte(bin_map)\n",
        "        _, cnts ,_= cv2.findContours(bin_img.copy(), cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "        s=0\n",
        "        r=0\n",
        "        cx=0.0\n",
        "        cy=0.0\n",
        "        for cont in cnts:\n",
        "          M = cv2.moments(cont)\n",
        "          if((M['m00']!=0)):\n",
        "            cx = int(M['m10']/M['m00'])\n",
        "            cy = int(M['m01']/M['m00'])\n",
        "          else:\n",
        "            continue\n",
        "\n",
        "\n",
        "          list_with_more_contours.append((cx,cy))\n",
        "\n",
        "        if(len(list_with_more_contours)>1):\n",
        "          for k in range(0,len(list_with_more_contours)):\n",
        "            dist=self.calculateDistance(list_with_more_contours[k][0],list_with_more_contours[k][1],target_center_coordinates[0],target_center_coordinates[1])\n",
        "            internal_list_distance.append(dist)\n",
        "\n",
        "          min_index=np.argmin(internal_list_distance)\n",
        "\n",
        "          min_value=list_with_more_contours[min_index]\n",
        "          self.list_maximal_values_batches.append(tuple(min_value))\n",
        "          list_with_more_contours=[]\n",
        "        else:\n",
        "          if(len(list_with_more_contours)>0):\n",
        "            self.list_maximal_values_batches.append(list_with_more_contours[0])\n",
        "            list_with_more_contours=[]\n",
        "          else:\n",
        "            self.list_maximal_values_batches.append((0,0))\n",
        "\n",
        "\n",
        "      else:\n",
        "        self.list_maximal_values_batches.append((0,0))\n",
        "\n",
        "      length_batch=len(self.list_maximal_values_batches)\n",
        "      return self.list_maximal_values_batches[length_batch-1]\n",
        "\n",
        "\n",
        "    def calculateDistance(self, x1,y1,x2,y2):\n",
        "      dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "      return dist\n",
        "\n",
        "    def calculate_metrics(self, target_list,output_list):\n",
        "      error_threshold=10\n",
        "      true_positive=0\n",
        "      false_positive=0\n",
        "      true_negative=0\n",
        "      false_negative=0\n",
        "\n",
        "      for i in range(0,len(target_list)):\n",
        "\n",
        "\n",
        "        if(target_list[i]==(0,0)):\n",
        "          if output_list[i]!=(0,0):\n",
        "            false_positive+=1\n",
        "          else:\n",
        "            true_negative+=1\n",
        "        else:\n",
        "          if (output_list[i]!=(0,0)):\n",
        "\n",
        "            distance = self.calculateDistance(target_list[i][0],target_list[i][1],output_list[i][0],output_list[i][1])\n",
        "            if (distance < error_threshold):\n",
        "              true_positive+=1\n",
        "            else:\n",
        "              false_negative+=1\n",
        "          else:\n",
        "            false_negative+=1\n",
        "\n",
        "      list_metrics=[true_positive,true_negative,false_positive,false_negative]\n",
        "      return list_metrics\n",
        "\n",
        "    def calculating_metrics(self, metrics_list):\n",
        "      true_positive =  metrics_list[0]\n",
        "      true_negative  = metrics_list[1]\n",
        "      false_positive = metrics_list[2]\n",
        "      false_negative = metrics_list[3]\n",
        "\n",
        "      Precision=(true_positive)/(false_positive+true_positive)\n",
        "      Recall=(true_positive/(true_positive+false_negative))\n",
        "      IOU=(true_positive/(true_positive+false_positive+false_negative))\n",
        "      FDR=(false_positive/(false_positive+true_positive))\n",
        "      Accuracy=(true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative)\n",
        "\n",
        "      list_calculated_metrics=[Precision*100, Recall*100, FDR*100, IOU*100, Accuracy*100]\n",
        "\n",
        "      return list_calculated_metrics\n",
        "\n",
        "\n",
        "    def find_metrics(self, out_list, annotation_path):\n",
        "      output_list=[]\n",
        "      metrics_list=[]\n",
        "      out_erosion_list=[]\n",
        "\n",
        "      target_coordinates = self.get_coordinates(annotation_path)\n",
        "      out_erosion_list = self.erosion(out_list)\n",
        "\n",
        "\n",
        "\n",
        "      for i in range(0, len(out_erosion_list)):\n",
        "        output_list.append(self.findmaximal(t.from_numpy(out_erosion_list[i]), target_coordinates[i]))\n",
        "        #output_list.append(self.findmaximal(out_erosion_list[i].squeeze(0), target_coordinates[i]))\n",
        "\n",
        "\n",
        "\n",
        "      metrics_list = self.calculate_metrics(target_coordinates,output_list)\n",
        "\n",
        "      PostMetrics = self.calculating_metrics(metrics_list)\n",
        "      print(\"Precision: {:.1f} - Recall: {:.1f} - FDR: {:.1f} - IOU: {:.1f} - Accuracy: {:.1f}\"\n",
        "            .format(PostMetrics[0], PostMetrics[1], PostMetrics[2], PostMetrics[3], PostMetrics[4]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "batch_size = 1\n",
        "drop_last = True\n",
        "beta1 = 0.5\n",
        "\n",
        "sweaty_model_version = 1\n",
        "\n",
        "# Paths\n",
        "source_path = 'gdrive/My Drive/'\n",
        "model_path = source_path+'SoccerDatasetTrain/sweaty1/'\n",
        "val_images_path = model_path+'val/'\n",
        "test_images_path = model_path+'test/'\n",
        "\n",
        "train_root_dir= source_path+'Data/lab3/'\n",
        "train_anno_path = source_path+'Data/train_lab3.csv'\n",
        "\n",
        "val_root_dir= source_path+'Data/test/'\n",
        "val_anno_path = source_path+'Data/test.csv'\n",
        "\n",
        "test_root_dir= source_path+'Data/final_sequence_test/'\n",
        "test_anno_path = source_path+'Data/final_sequence.csv'\n",
        "\n",
        "\n",
        "sweaty_evaluator = Sweaty_ModelEvaluator(model_path, val_images_path, test_images_path, num_epochs)\n",
        "\n",
        "# Loading the dataset\n",
        "train_loader = sweaty_evaluator.data_loading(train_root_dir, train_anno_path, batch_size, shuffle=True)\n",
        "val_loader = sweaty_evaluator.data_loading(val_root_dir, val_anno_path, batch_size, shuffle=False)\n",
        "test_loader = sweaty_evaluator.data_loading(test_root_dir, test_anno_path, batch_size, shuffle=False)\n",
        "\n",
        "# SweatyNet model object creation\n",
        "if sweaty_model_version == 1:\n",
        "  sweaty_model = SweatyModel1().cuda().float()\n",
        "elif sweaty_model_version == 2:\n",
        "  sweaty_model = SweatyModel2().cuda().float()\n",
        "else:\n",
        "  sweaty_model = SweatyModel3().cuda().float()\n",
        "\n",
        "# MSE Loss function\n",
        "sweaty_criterion = nn.MSELoss()\n",
        "\n",
        "# Adam Optimitzer function\n",
        "sweaty_optimizer = t.optim.Adam(sweaty_model.parameters(), lr = learning_rate, betas = (beta1, 0.999))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "trained_model, train_loss_list, train_output = sweaty_evaluator.train_model(sweaty_model, train_loader)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Validating the model\n",
        "val_output, val_loss_list = sweaty_evaluator.validation_model(trained_model, val_loader)\n",
        "np.save('gdrive/My Drive/Dataset/sweaty_val_out_final_project_1', val_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Testing the model\n",
        "test_output, test_loss_list = sweaty_evaluator.test_model(trained_model, test_loader)\n",
        "\n",
        "\n",
        "\n",
        "# Plotting Loss\n",
        "#plot_loss(train_loss_list, model_path+'sweaty2_train_loss_final_1000.png')\n",
        "sweaty_evaluator.plot_loss(val_loss_list, model_path+'sweaty1_val_loss.png')\n",
        "sweaty_evaluator.plot_loss(test_loss_list, model_path+'sweaty1_test_loss.png')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_target_list=[]\n",
        "for i, batch in enumerate(test_loader):\n",
        "  test_target_list.append(batch['labels'])\n",
        "\n",
        "print(len(test_target_list))\n",
        "\n",
        "val_target_list=[]\n",
        "for i, batch in enumerate(val_loader):\n",
        "  val_target_list.append(batch['labels'])\n",
        "\n",
        "print(len(val_target_list))\n",
        "# Find Recall, FDR & IoU for SweatyNet\n",
        "\n",
        "sweaty_postprocess = PostProcessing()\n",
        "print('-------Sweaty Validation Set-------')\n",
        "#sweaty_postprocess.find_metrics(val_target_list, val_anno_path, val_output, 'sweaty')\n",
        "sweaty_postprocess.find_metrics(val_output, val_anno_path)\n",
        "print('\\n\\n-------Sweaty Test Set-------')\n",
        "sweaty_postprocess.find_metrics(test_output, test_anno_path)\n",
        "\n",
        "#sweaty_postprocess.find_metrics(test_target_list, test_anno_path, test_output, 'sweaty')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## https://github.com/ndrplz/ConvLSTM_pytorch\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
        "        \"\"\"\n",
        "        Initialize ConvLSTM cell.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size: (int, int)\n",
        "            Height and width of input tensor as (height, width).\n",
        "        input_dim: int\n",
        "            Number of channels of input tensor.\n",
        "        hidden_dim: int\n",
        "            Number of channels of hidden state.\n",
        "        kernel_size: (int, int)\n",
        "            Size of the convolutional kernel.\n",
        "        bias: bool\n",
        "            Whether or not to add the bias.\n",
        "        \"\"\"\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.height, self.width = input_size\n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "        self.bias        = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)).cuda(),\n",
        "                Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)).cuda())\n",
        "\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
        "                 batch_first=False, bias=True, return_all_layers=False):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self._check_kernel_size_consistency(kernel_size)\n",
        "\n",
        "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
        "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
        "        hidden_dim  = self._extend_for_multilayer(hidden_dim, num_layers)\n",
        "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
        "            raise ValueError('Inconsistent list length.')\n",
        "\n",
        "        self.height, self.width = input_size\n",
        "\n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
        "\n",
        "            cell_list.append(ConvLSTMCell(input_size=(self.height, self.width),\n",
        "                                          input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "    def forward(self, input_tensor, hidden_state=None):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor: todo\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state: todo\n",
        "            None. todo implement stateful\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        \"\"\"\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        # Implement stateful ConvLSTM\n",
        "        if hidden_state is not None:\n",
        "            raise  NotImplementedError ()\n",
        "        else:\n",
        "            hidden_state = self._init_hidden(batch_size=input_tensor.size(0))\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list   = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = input_tensor\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "\n",
        "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
        "                                                 cur_state=[h, c])\n",
        "\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list   = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.cell_list[i].init_hidden(batch_size))\n",
        "        return init_states\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_kernel_size_consistency(kernel_size):\n",
        "        if not (isinstance(kernel_size, tuple) or\n",
        "                    (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
        "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
        "\n",
        "    @staticmethod\n",
        "    def _extend_for_multilayer(param, num_layers):\n",
        "        if not isinstance(param, list):\n",
        "            param = [param] * num_layers\n",
        "        return param\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Convlstm_PostProcessing:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.list_maximal_values_batches = []\n",
        "\n",
        "    # Creating the test coordinates list of the ball\n",
        "    def get_coordinates(self, annotation_path):\n",
        "\n",
        "        target_coordinates = []\n",
        "        annotations_frame = pd.read_csv(annotation_path)\n",
        "\n",
        "        for index, rows in annotations_frame.iterrows():\n",
        "          _, _, _, x1, y1, x2, y2, _, _, _, _ = rows\n",
        "\n",
        "          x1 = x1 / 4\n",
        "          x2 = x2 / 4\n",
        "          y1 = y1 / 4\n",
        "          y2 = y2 / 4\n",
        "          x = (x1 + x2) / 2\n",
        "          y = (y1 + y2) / 2\n",
        "          center = (x,y)\n",
        "          target_coordinates.append(center)\n",
        "\n",
        "        return target_coordinates\n",
        "\n",
        "    def erosion(self, output_list):\n",
        "        erosion_list = []\n",
        "\n",
        "        kernel = np.ones((4,4),np.uint8)\n",
        "\n",
        "        for i in range(0, len(output_list)):\n",
        "          out = (output_list[i].reshape(1,128,160)).cpu().detach().numpy()\n",
        "\n",
        "          erosion_output = cv2.erode(out, kernel, iterations = 1)\n",
        "          erosion_list.append(erosion_output)\n",
        "\n",
        "        return erosion_list\n",
        "\n",
        "\n",
        "\n",
        "    def findmaximal(self, test_output_matrix_image, target_center_coordinates):\n",
        "      z=test_output_matrix_image.permute(1,2,0)\n",
        "      z=test_output_matrix_image\n",
        "      z.to(dtype=t.float32)\n",
        "      list_with_more_contours=[]\n",
        "      internal_list_distance=[]\n",
        "\n",
        "      center_coord_targ=target_center_coordinates\n",
        "      number=np.count_nonzero(z.cpu().detach().numpy())\n",
        "      if(number>0):\n",
        "\n",
        "        prob_map=z.cpu().detach().numpy()\n",
        "        prob_map = np.squeeze(prob_map)\n",
        "        maximum_value=np.amax(prob_map)\n",
        "        thresh=0.8*maximum_value\n",
        "        bin_map = prob_map > thresh\n",
        "        bin_img = img_as_ubyte(bin_map)\n",
        "        _, cnts ,_= cv2.findContours(bin_img.copy(), cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "        s=0\n",
        "        r=0\n",
        "\n",
        "        cx=0.0\n",
        "        cy=0.0\n",
        "        #print(\"contours\",cnts)\n",
        "        for cont in cnts:\n",
        "          M = cv2.moments(cont)\n",
        "          if((M['m00']!=0)):\n",
        "            cx = int(M['m10']/M['m00'])\n",
        "            cy = int(M['m01']/M['m00'])\n",
        "          else:\n",
        "            continue\n",
        "\n",
        "\n",
        "          list_with_more_contours.append((cx,cy))\n",
        "\n",
        "        if(len(list_with_more_contours)>1):\n",
        "          #print(\"list_with_more_contours\",list_with_more_contours)\n",
        "          for k in range(0,len(list_with_more_contours)):\n",
        "            dist=self.calculateDistance(list_with_more_contours[k][0],list_with_more_contours[k][1],target_center_coordinates[0],target_center_coordinates[1])\n",
        "            internal_list_distance.append(dist)\n",
        "\n",
        "          min_index=np.argmin(internal_list_distance)\n",
        "\n",
        "          min_value=list_with_more_contours[min_index]\n",
        "          self.list_maximal_values_batches.append(tuple(min_value))\n",
        "          list_with_more_contours=[]\n",
        "        else:\n",
        "\n",
        "          if(len(list_with_more_contours)>0):\n",
        "            #print(list_with_more_contours)\n",
        "            self.list_maximal_values_batches.append(list_with_more_contours[0])\n",
        "            list_with_more_contours=[]\n",
        "          else:\n",
        "            self.list_maximal_values_batches.append((0,0))\n",
        "\n",
        "\n",
        "      else:\n",
        "        self.list_maximal_values_batches.append((0,0))\n",
        "\n",
        "      length_batch=len(self.list_maximal_values_batches)\n",
        "      return self.list_maximal_values_batches[length_batch-1]\n",
        "\n",
        "\n",
        "    def calculateDistance(self, x1,y1,x2,y2):\n",
        "      dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "      return dist\n",
        "\n",
        "    def calculate_metrics(self, target_list,output_list):\n",
        "      error_threshold=5\n",
        "      true_positive=0\n",
        "      false_positive=0\n",
        "      true_negative=0\n",
        "      false_negative=0\n",
        "\n",
        "      #print('Target: ',target_list)\n",
        "      #print('Output: ',output_list)\n",
        "\n",
        "      for i in range(0,len(target_list)):\n",
        "\n",
        "        #print('Target: ', target_list[i])\n",
        "        #print('Output: ', output_list)\n",
        "        if(target_list[i]==(0,0)):\n",
        "          if output_list[i]!=(0,0):\n",
        "            false_positive+=1\n",
        "          else:\n",
        "            true_negative+=1\n",
        "        else:\n",
        "          if (output_list[i]!=(0,0)):\n",
        "\n",
        "            distance = self.calculateDistance(target_list[i][0],target_list[i][1],output_list[i][0],output_list[i][1])\n",
        "            if (distance < error_threshold):\n",
        "              true_positive+=1\n",
        "            else:\n",
        "              false_negative+=1\n",
        "          else:\n",
        "            false_negative+=1\n",
        "\n",
        "      list_metrics=[true_positive,true_negative,false_positive,false_negative]\n",
        "      return list_metrics\n",
        "\n",
        "    def calculating_metrics(self, metrics_list):\n",
        "      true_positive =  metrics_list[0]\n",
        "      true_negative  = metrics_list[1]\n",
        "      false_positive = metrics_list[2]\n",
        "      false_negative = metrics_list[3]\n",
        "\n",
        "      Precision=(true_positive)/(false_positive+true_positive)\n",
        "      Recall=(true_positive/(true_positive+false_negative))\n",
        "      IOU=(true_positive/(true_positive+false_positive+false_negative))\n",
        "      FDR=(false_positive/(false_positive+true_positive))\n",
        "      Accuracy=(true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative)\n",
        "\n",
        "      list_calculated_metrics=[Precision*100, Recall*100, FDR*100, IOU*100, Accuracy*100]\n",
        "\n",
        "      return list_calculated_metrics\n",
        "\n",
        "    def find_metrics(self, target_list, annotation_path, out_list, findmetric):\n",
        "      #print('target_list',len(target_list))\n",
        "      output_list=[]\n",
        "      metrics_list=[]\n",
        "      out_erosion_list=[]\n",
        "      target_lis=[]\n",
        "      target_coordinates = self.get_coordinates(annotation_path)\n",
        "      #out_erosion_list_target = self.erosion(target_list)\n",
        "\n",
        "      out_erosion_list_output = self.erosion(out_list)\n",
        "\n",
        "      if findmetric == 'convlstm':\n",
        "          for i in range(0, len(target_list)):\n",
        "            #print(target_list[i].shape)\n",
        "            target_lis.append(self.findmaximal((target_list[i].squeeze(0)), target_coordinates[i]))\n",
        "          for i in range(0, len(out_erosion_list_output)):\n",
        "            output_list.append(self.findmaximal(t.from_numpy(out_erosion_list_output[i]), target_lis[i]))\n",
        "        #print(\"output list length\",len(target_coordinates_centers),len(output_list))\n",
        "          metrics_list = self.calculate_metrics(target_lis, output_list)\n",
        "\n",
        "      else:\n",
        "          for i in range(0, len(out_erosion_list_output)):\n",
        "            output_list.append(self.findmaximal(t.from_numpy(out_erosion_list_output[i]), target_coordinates[i]))\n",
        "          metrics_list = self.calculate_metrics(target_coordinates, output_list)\n",
        "\n",
        "      PostMetrics = self.calculating_metrics(metrics_list)\n",
        "      print(\"Precision: {:.1f} - Recall: {:.1f} - FDR: {:.1f} - IOU: {:.1f} - Accuracy: {:.1f}\"\n",
        "            .format(PostMetrics[0], PostMetrics[1], PostMetrics[2], PostMetrics[3], PostMetrics[4]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Convlstm_ModelEvaluator:\n",
        "\n",
        "    def __init__(self, model_path, conv_img_path):\n",
        "      self.model_path = model_path\n",
        "      self.conv_img_path = conv_img_path\n",
        "\n",
        "    def convlstm_train(self, convlstm_model, val_loader, val_output):\n",
        "\n",
        "        convlstm_output=[]\n",
        "        num_epochs = 50\n",
        "        seq_len = 5\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            iter = 0\n",
        "\n",
        "            for i, batch in enumerate(val_loader):\n",
        "\n",
        "                batch_labels = batch['labels'].permute(0, 3, 1, 2).cuda().float()\n",
        "                target = batch_labels\n",
        "                input = val_output[i]\n",
        "\n",
        "                for k in range(iter, (seq_len-1)+i):\n",
        "\n",
        "                    if(i+4 <= len(val_loader.dataset)-1):\n",
        "                        input = t.cat((input, val_output[k]), dim = 0)\n",
        "                        target = t.cat((target, val_loader.dataset[k]['labels'].permute(2, 0, 1).unsqueeze(0).cuda().float()), dim = 0)\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "\n",
        "                target = target[-1].unsqueeze(0)\n",
        "                input = input.unsqueeze(0)\n",
        "\n",
        "                convlstm_model.zero_grad()\n",
        "                conv_out = convlstm_model(input.detach(), hidden_state=None)\n",
        "\n",
        "                convlstm_loss = convlstm_criterion(conv_out[1][0][0], target)\n",
        "\n",
        "                convlstm_loss.backward()\n",
        "                convlstm_optimizer.step()\n",
        "\n",
        "                target_img = self.conv_img_path+'convlstm\\sweaty1_lab3_convtrain_target'+str(i)+'.png'\n",
        "                output_img = self.conv_img_path+'convlstm\\sweaty1_lab3_convtrain_output'+str(i)+'.png'\n",
        "\n",
        "                if iter % 5 == 0:\n",
        "                  torchvision.utils.save_image(target, target_img)\n",
        "                  torchvision.utils.save_image(conv_out[1][0][0][0], output_img)\n",
        "\n",
        "                  #Sweaty_ModelEvaluator.visualize_output((target.reshape(1,128,160)).cpu().detach().numpy(), 'Target')\n",
        "                  #Sweaty_ModelEvaluator.visualize_output((conv_out[1][0][0][0]).cpu().detach().numpy(), 'Output')\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "            print('Epoch: {}/{} - Loss: {:.6f}'.format(epoch+1, num_epochs, convlstm_loss.data))\n",
        "            t.save(convlstm_model.state_dict(), self.model_path+'convlstm_sweatynet1_trained_model_'+str(epoch)+'.pkl')\n",
        "\n",
        "        return convlstm_model\n",
        "\n",
        "\n",
        "    def convlstm_test(self, convlstm_trained, test_loader, test_output):\n",
        "\n",
        "        convlstm_output=[]\n",
        "        convlstm_target=[]\n",
        "        seq_len = 5\n",
        "\n",
        "        iter = 0\n",
        "\n",
        "        for i, batch in enumerate(test_loader):\n",
        "\n",
        "            batch_labels = batch['labels'].permute(0, 3, 1, 2).cuda().float()\n",
        "            target = batch_labels\n",
        "            input = test_output[i]\n",
        "\n",
        "            for k in range(iter, (seq_len-1)+i):\n",
        "                if(i+4 <= len(test_loader.dataset)-1):\n",
        "                  input = t.cat((input, test_output[k]), dim = 0)\n",
        "                  target = t.cat((target, test_loader.dataset[k]['labels'].permute(2, 0, 1).unsqueeze(0).cuda().float()), dim = 0)\n",
        "                else:\n",
        "                  break\n",
        "\n",
        "            target = target[-1].unsqueeze(0)\n",
        "            input = input.unsqueeze(0)\n",
        "\n",
        "\n",
        "            conv_out = convlstm_trained(input, hidden_state=None)\n",
        "            convlstm_output.append(conv_out[1][0][0])\n",
        "            convlstm_target.append(target)\n",
        "\n",
        "            target_img = self.conv_img_path+'sweaty1_lab3_convtest_target'+str(i)+'.png'\n",
        "            output_img = self.conv_img_path+'sweaty1_lab3_convtest_output'+str(i)+'.png'\n",
        "            torchvision.utils.save_image(target, target_img)\n",
        "            torchvision.utils.save_image(conv_out[1][0][0][0], output_img)\n",
        "            #Sweaty_ModelEvaluator.visualize_output((target.reshape(1,128,160)).cpu().detach().numpy(), 'Target')\n",
        "            #Sweaty_ModelEvaluator.visualize_output((conv_out[1][0][0][0]).cpu().detach().numpy(), 'Output')\n",
        "\n",
        "            iter += 1\n",
        "\n",
        "        return convlstm_output, convlstm_target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Conv LSTM model object creation\n",
        "height, width = 128, 160\n",
        "convlstm_model = ConvLSTM(input_size=(height, width),\n",
        "                 input_dim=1,\n",
        "                 hidden_dim=[32,1],\n",
        "                 kernel_size=(3,3),\n",
        "                 num_layers=2,\n",
        "                 batch_first=True,\n",
        "                 bias=False,\n",
        "                 return_all_layers=False)\n",
        "\n",
        "# Initializing the MSE Loss function\n",
        "convlstm_criterion = nn.MSELoss()\n",
        "\n",
        "# Initializing the Adam Optimitzer function\n",
        "convlstm_optimizer = t.optim.Adam(convlstm_model.parameters(), lr = learning_rate)\n",
        "\n",
        "source_path = 'gdrive/My Drive/'\n",
        "model_path = source_path+'SoccerDatasetTrain/sweaty1/'\n",
        "conv_img_path = source_path+'SoccerDatasetTrain/sweaty1/conv/'\n",
        "convlstm_eval = Convlstm_ModelEvaluator(model_path, conv_img_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "convlstm_trained = convlstm_eval.convlstm_train(convlstm_model, val_loader, val_output)\n",
        "\n",
        "\n",
        "convlstm_model.load_state_dict(t.load(model_path+'convlstm_sweatynet1_trained_model.pkl'))\n",
        "convlstm_trained = convlstm_model\n",
        "\n",
        "\n",
        "convlstm_output, convlstm_target = convlstm_eval.convlstm_test(convlstm_trained, test_loader, test_output)\n",
        "\n",
        "\n",
        "\n",
        "# Find Recall, FDR & IoU for SweatyNet + Conv LSTM\n",
        "\n",
        "convlstm_postprocess = Convlstm_PostProcessing()\n",
        "print('\\n\\n-------Convlstm Test Set-------')\n",
        "convlstm_postprocess.find_metrics(convlstm_target, test_anno_path, convlstm_output, 'convlstm')\n"
      ],
      "metadata": {
        "id": "NXTanRbULMBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from collections import deque\n",
        "from imutils.video import VideoStream\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import imutils\n",
        "import time\n",
        "import sys\n",
        "\n",
        "#coord of polygon in frame::: [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]\n",
        "coord=[[236,193],[462,193],[236,267],[462,267]]\n",
        "\n",
        "#Distance between two vertical lines in (meter/ft)\n",
        "dist = 12\n",
        "\n",
        "timeMark = time.time()\n",
        "dtFIL = 0\n",
        "#tim1 = time.time()\n",
        "tim1 = timeMark\n",
        "\n",
        "#fourcc = cv2.VideoWriter_fourcc(*“mp4v”)\n",
        "out1 = cv2.VideoWriter('Ball.mp4',0x00000021, 60.0, (640, 360))\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-v\", \"--video\",\n",
        "                help=\"path to the (optional) video file\")\n",
        "ap.add_argument(\"-b\", \"--buffer\", type=int, default=64,\n",
        "                help=\"max buffer size\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# define the lower and upper boundaries of the \"green\"\n",
        "# ball in the HSV color space, then initialize the\n",
        "# list of tracked points\n",
        "greenLower = (29, 86, 6)\n",
        "greenUpper = (64, 255, 255)\n",
        "pts = deque(maxlen=args[\"buffer\"])\n",
        "\n",
        "# if a video path was not supplied, grab the reference\n",
        "# to the webcam\n",
        "if not args.get(\"video\", False):\n",
        "    vs = VideoStream(src=0).start()\n",
        "\n",
        "# otherwise, grab a reference to the video file\n",
        "else:\n",
        "    vs = cv2.VideoCapture(args[\"video\"])\n",
        "\n",
        "# allow the camera or video file to warm up\n",
        "time.sleep(2.0)\n",
        "\n",
        "# keep looping\n",
        "# while True:\n",
        "# grab the current frame\n",
        "#\tframe = vs.read()\n",
        "\n",
        "# handle the frame from VideoCapture or VideoStream\n",
        "#\tframe = frame[1] if args.get(\"video\", False) else frame\n",
        "\n",
        "# if we are viewing a video and we did not grab a frame,\n",
        "# then we have reached the end of the video\n",
        "#\tif frame is None:\n",
        "#\t\tbreak\n",
        "while True:\n",
        "    # grab the current frame\n",
        "    frame = vs.read()\n",
        "\n",
        "    # handle the frame from VideoCapture or VideoStream\n",
        "    frame = frame[1] if args.get(\"video\", False) else frame\n",
        "\n",
        "    # if we are viewing a video and we did not grab a frame,\n",
        "    # then we have reached the end of the video\n",
        "    if frame is None:\n",
        "        break\n",
        "\n",
        "    # resize the frame, blur it, and convert it to the HSV\n",
        "    # color space\n",
        "    frame = imutils.resize(frame, width=640, height=360)\n",
        "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
        "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # construct a mask for the color \"green\", then perform\n",
        "    # a series of dilations and erosions to remove any small\n",
        "    # blobs left in the mask\n",
        "    mask = cv2.inRange(hsv, greenLower, greenUpper)\n",
        "    mask = cv2.erode(mask, None, iterations=2)\n",
        "    mask = cv2.dilate(mask, None, iterations=2)\n",
        "\n",
        "    # find contours in the mask and initialize the current\n",
        "    # (x, y) center of the ball\n",
        "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    center = None\n",
        "\n",
        "    cv2.line(frame, (coord[0][0], coord[0][1]), (coord[1][0], coord[1][1]), (0, 0, 255), 2)  # First horizontal line\n",
        "    cv2.line(frame, (coord[0][0], coord[0][1]), (coord[2][0], coord[2][1]), (0, 0, 255), 2)  # Vertical left line\n",
        "    cv2.line(frame, (coord[2][0], coord[2][1]), (coord[3][0], coord[3][1]), (0, 0, 255), 2)  # Second horizontal line\n",
        "    cv2.line(frame, (coord[1][0], coord[1][1]), (coord[3][0], coord[3][1]), (0, 0, 255), 2)  # Vertical right line\n",
        "\n",
        "    # only proceed if at least one contour was found\n",
        "    if len(cnts) > 0:\n",
        "        # find the largest contour in the mask, then use\n",
        "        # it to compute the minimum enclosing circle and\n",
        "        # centroid\n",
        "        c = max(cnts, key=cv2.contourArea)\n",
        "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
        "        M = cv2.moments(c)\n",
        "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
        "\n",
        "        # only proceed if the radius meets a minimum size\n",
        "        if radius > 10:\n",
        "            # draw the circle and centroid on the frame,\n",
        "            # then update the list of tracked points\n",
        "            cv2.circle(frame, (int(x), int(y)), int(radius),\n",
        "                       (0, 255, 255), 2)\n",
        "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
        "\n",
        "\n",
        "        if (x <= coord[1][0]):  # coord[0][0] and y == coord[0][1])\n",
        "            cv2.line(frame, (coord[1][0], coord[1][1]), (coord[3][0], coord[3][1]), (0, 255, 0),2)  # Changes line color to green\n",
        "            #tim1 = current_frame_number_list = [0]  # Initial time\n",
        "            print(\"Ball Entered.\")\n",
        "\n",
        "        if ( x <= coord[0][0]):  # (x >= coord[2][0] and y == coord[2][1]):\n",
        "            cv2.line(frame, (coord[0][0], coord[0][1]), (coord[2][0], coord[2][1]), (0, 255, 0),2)  # Changes line color to green\n",
        "            tim2 = time.time()  # Final time\n",
        "            print(\"Ball Left.\")\n",
        "            # We know that distance is 3m\n",
        "            print(\"Speed in (ft/s) is:\", dist / ((tim2 - tim1)))\n",
        "            print(\"Time of travel is:\", (tim2 - tim1))\n",
        "            print(\"Time Entry is:\", tim1)\n",
        "            print(\"Time Exit is:\", tim2)\n",
        "\n",
        "    # update the points queue\n",
        "    pts.appendleft(center)\n",
        "\n",
        "    # loop over the set of tracked points\n",
        "    for i in range(1, len(pts)):\n",
        "        # if either of the tracked points are None, ignore\n",
        "        # them\n",
        "        if pts[i - 1] is None or pts[i] is None:\n",
        "            continue\n",
        "\n",
        "        # otherwise, compute the thickness of the line and\n",
        "        # draw the connecting lines\n",
        "        thickness = int(np.sqrt(args[\"buffer\"] / float(i + 1)) * 1.5)\n",
        "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 150), thickness)\n",
        "\n",
        "    # show the frame to our screen\n",
        "    dt = time.time() - timeMark\n",
        "    timeMark = time.time()\n",
        "    dtFIL = .9 * dtFIL + .1 * dt\n",
        "    fps = 1 / dtFIL\n",
        "    #print('fps: ', fps)\n",
        "    out1.write(frame)\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "    # if the 'q' key is pressed, stop the loop\n",
        "    if key == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "# if we are not using a video file, stop the camera video stream\n",
        "if not args.get(\"video\", False):\n",
        "\tvs.stop()\n",
        "\n",
        "# otherwise, release the camera\n",
        "else:\n",
        "\tvs.release()\n",
        "\n",
        "# close all windows\n",
        "out1.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "RiC3VmprL1R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load YOLO model\n",
        "weights_path = 'yolov2.weights'  # Update with the correct YOLO weights file path\n",
        "config_path = 'yolov2.cfg'       # Update with the correct YOLO config file path\n",
        "net = cv2.dnn.readNet(weights_path, config_path)\n",
        "\n",
        "# Set up YOLO model to detect balls\n",
        "net.setInputSize(416, 416)\n",
        "net.setInputScale(1.0 / 255)\n",
        "net.setInputSwapRB(True)\n",
        "\n",
        "# Define video capture\n",
        "video_path = '/content/Recording 2024-11-05 230942.mp4'  # Replace with the path to your video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Prepare the frame for YOLO\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Run detection\n",
        "    detections = net.forward()\n",
        "\n",
        "    # Process detections\n",
        "    for detection in detections[0, 0, :, :]:\n",
        "        confidence = float(detection[2])\n",
        "        class_id = int(detection[1])\n",
        "        if confidence > 0.5 and class_id == 0:  # Assuming \"ball\" class is labeled as 0\n",
        "            box_x = int(detection[3] * frame.shape[1])\n",
        "            box_y = int(detection[4] * frame.shape[0])\n",
        "            box_width = int(detection[5] * frame.shape[1])\n",
        "            box_height = int(detection[6] * frame.shape[0])\n",
        "\n",
        "            # Draw bounding box around detected ball\n",
        "            cv2.rectangle(frame, (box_x, box_y), (box_x + box_width, box_y + box_height), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, \"Ball\", (box_x, box_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Display frame with detections\n",
        "    cv2.imshow(\"Ball Detection\", frame)\n",
        "\n",
        "    # Break on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Ihoalf5ENAuq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}